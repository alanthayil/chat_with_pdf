{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"docs/papers/paper_1.pdf\"),\n",
    "    PyPDFLoader(\"docs/papers/paper_2.pdf\"),\n",
    "    PyPDFLoader(\"docs/papers/paper_3.pdf\"),\n",
    "    PyPDFLoader(\"docs/papers/paper_4.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9631675619330512"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7710630976675917"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7596682675219103"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./docs/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"is there an abstract\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9  Summary  and  outlook 78\\nmore  efficient  strategy  for  real  data  set  creation  can  also  be  significantly  reduced.  \\nImprovements  in  synthetic  PBR  data  set  creation  could  also  reduce  or  completely  \\neliminate  the  need  for  real  training  data  in  the  future.Machine Translated by Google'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about yolox?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='\\x08\\x04\\x08\\x0c\\x03\\x06\\x05\\x07\\x03\\x0b\\t\\x04\\x05\\x08\\x03\\t\\x08\\x08\\x03\\x07\\x05\\x04\\x03\\t\\x08\\x0b\\x03\\x07\\x05\\x05\\x03\\t\\t\\x0b\\n\\x08\\x0b\\x03\\x0b\\x05\\x06\\x03\\x05\\x08\\x0c\\x03\\r\\x05\\x06\\x03\\x0b\\x08\\x08\\r\\x03\\x08\\x08\\n\\x03\\x06\\r\\x03\\r\\t\\x05\\x06\\x08\\n\\x03\\x0c\\x05\\x04\\x03\\r\\x08\\x0c\\x03\\x05\\x05\\x05\\x03\\n\\x08\\x07\\x03\\x07\\x0c\\x03\\x07\\x08\\t\\x03\\x06\\r\\x03\\x05\\n\\x14\\x07\\n\\x03\\x0b\\x0c\\x03\\r\\x07\\r\\x03\\n\\r\\x03\\n\\x06\\x07\\x03\\t\\x05\\n\\x03\\x08\\x06\\x08\\x03\\x06\\x05\\n\\x03\\n\\x11\\x08\\x08\\x03\\t\\x05\\x05\\x03\\x05\\x08\\n\\x03\\x08\\x05\\x06\\x03\\x07\\x10\\x08\\x0c\\x03\\x06\\x05\\x07\\x03\\x0b\\t\\x04\\x05\\x08\\x03\\t\\x16\\t\\x04\\x03\\x08\\x05\\t\\x03\\x07\\x05\\n\\x03\\x07\\x0f\\x1b\\x1b\\x1c\\x19\\x1c\\x1a\\x1f\"\\x0e\\x1a\"\\x08\\x08\\x03\\x0b\\x12\\x18\\x1f \\x0e\\x1a\"\\x02\\x1e\\x17\\x13\\x10\\x13\\x16\\x01\\x15\\x1c\\x1f$\\x08\\x07\\x03\\n\\x06\\x04\\x03\\n\\x05\\x04\\x03\\x06\\x06\\x05\\x03\\x0c\\x05\\x04\\x03\\x08\\x08\\x06\\x03\\x0c\\x06\\x07\\x03\\t\\x05\\n\\x03\\x08\\x06\\x08\\x03\\x06\\x05\\n\\x03\\n\\x08\\x06\\x03\\x0b\\x0c\\x08\\x05\\x03\\t\\x08\\x05\\x03\\r\\x0b\\x03\\x0c\\x08\\x05\\x0b\\x03\\x0b\\x0f\\x1b\\x1b\\x1c\\x19\\x1c\\x1a\\x1f\"\\x0e\\x1a\"\\x08\\x04\\x03\\x05\\x0b\\x03\\n\\x08\\x05\\x03\\x0b\\x05\\x08\\x03\\x0c\\x07\\x08\\x03\\n\\r\\x03\\x06\\x08\\x08\\x05\\x0c\\x03\\x0b\\x08\\x04\\x03\\t\\x05\\x06\\x03\\t\\x08\\t\\x03\\x0b\\x06\\x05\\x03\\x0b\\x08\\x07\\x05\\n\\x03\\x0b\\x08\\n\\x03\\n\\x06\\n\\x03\\n\\x08\\x0b\\x03\\t\\x06\\x0b\\x08\\x0b\\x03\\r\\x07\\x07\\x03\\x0c\\x08\\r\\x03\\x0b\\x08\\x05\\x03\\x0c\\t\\x05\\x03\\t\\x0b\\x05\\x03\\t\\x17\\x13\\x10\\x13#\\t\\x02\\x10\\x17\\x13\\x10\\x13\\x16\\x02\\x10\\x17\\x13\\x10\\x13#\\x07\\x17\\x13\\x10\\x13\\x16\\x02\\x0e\\x18!\\x1d\\x12\\x1a\"\\t\\x07\\n\\x17\\x13\\x10\\x13#\\t\\x17\\x13\\x10\\x13\\x16\\n39404142434445464748495051\\n58111417202326293235384144COCO AP (%)V100 batch 1 Latency (ms)YOLOX-LYOLOv5-LYOLOX-DarkNet53YOLOv5-Darknet53EfficientDet\\n2123252729313335373941\\n0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 10.5 11.5 12.5COCO AP (%)\\nNumber of parameters (M)YOLOX -Nano\\nNanoDetYOLOv4 -TinyYOLOX -Tiny\\nEfficientDet -Lite0EfficientDet -Lite3YOLOX -S\\nPPYOLO -TinyEfficientDet -Lite2\\nEfficientDet -Lite1\\nFigure 1: Speed-accuracy trade-off of accurate models (top) and Size-accuracy curve of lite models on mobile devices\\n(bottom) for YOLOX and other state-of-the-art object detectors.\\nAbstract\\nIn this report, we present some experienced improve-\\nments to YOLO series, forming a new high-performance\\ndetector â€” YOLOX. We switch the YOLO detector to an\\nanchor-free manner and conduct other advanced detection\\ntechniques, i.e., a decoupled head and the leading label\\nassignment strategy SimOTA to achieve state-of-the-art re-\\nsults across a large scale range of models: For YOLO-\\nNano with only 0.91M parameters and 1.08G FLOPs, we', metadata={'page': 0, 'source': 'docs/papers/paper_3.pdf'})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='[16]9\\nWith  YOLOX,  further  changes  were  implemented  in  2021  based  on  YOLOv3  and  \\nsignificant  improvements  were  achieved.This  will  be  expanded  in  2018  with  YOLOv3  to  include  skip  connections  and  thus  \\nbecome  a  ResNet,  which  also  made  further  depth  possible.  This  gave  the  feature  \\nextractor  53  convolutional  layers  and  the  name  Darknet-53  [20].\\nAnother  change  of  YOLOX  compared  to  the  other  published  versions  from  YOLOv2  is  \\nthat  the  architecture  was  again  designed  without  anchor  boxes,  as  these  generalize  \\nmore  poorly  and  increase  complexity,  which  could  be  a  limitation  for  further  reducing  \\nlatency  [17].  Furthermore,  in  recent  years,  anchor-free  detectors  have  achieved  results  \\ncomparable  to  anchor-based  ones  [23].YOLOXSince  the  release  of  YOLO,  there  have  been  some  efforts  to  improve  the  original  \\napproach.  In  2017,  anchor  boxes  were  introduced  with  YOLOv2,  which  are  based  on  \\nthe  region  proposal  networks  of  Faster  R-CNN  and  represent  reference  boxes  of  the  \\nobjects  with  different  scaling  and  different  aspect  ratios  [18];  [19].  YOLOv2  also  has  a  \\nnew  feature  extractor  CNN  consisting  of  19  convolutional  and  five  pooling  layers,  the  \\nDarknet-19  [19].\\nthe  YOLOX  network  used  in  this  work  is  based  on  YOLOv3  [17].Further  development  of  YOLOMachine Translated by Google', metadata={'page': 17, 'source': 'docs/papers/paper_4.pdf'})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 0, 'source': 'docs/papers/paper_3.pdf'}\n",
      "{'page': 17, 'source': 'docs/papers/paper_4.pdf'}\n",
      "{'page': 5, 'source': 'docs/papers/paper_3.pdf'}\n",
      "{'page': 1, 'source': 'docs/papers/paper_3.pdf'}\n",
      "{'page': 0, 'source': 'docs/papers/paper_3.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
