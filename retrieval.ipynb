{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldb = Chroma.from_texts(texts, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(page_content='The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.similarity_search(question, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.max_marginal_relevance_search(question,k=2, fetch_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about yolox?\"\n",
    "docs_ss = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+3.3 AR C(#4−#8) w.r.t. ZebraPose [42].\\n4.3. 2D Object Detection Results\\nAs shown in Tab. 4, the YOL'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ss[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Method ...based on Year Data ...type AP CTime\\n1 GDRNPPDet YOLOX 2022 RGB PBR+real 77.3 .081\\n2 GDRN'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ss[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_mmr = vectordb.max_marginal_relevance_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+3.3 AR C(#4−#8) w.r.t. ZebraPose [42].\\n4.3. 2D Object Detection Results\\nAs shown in Tab. 4, the YOL'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Figure D.3: Qualitative Results on YCB-V [60]. For each image, we visualize the 6D poses by renderin'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about yolox in the second paper?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=3,\n",
    "    filter={\"source\":\"docs/papers/paper_2.pdf\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 6, 'source': 'docs/papers/paper_2.pdf'}\n",
      "{'page': 6, 'source': 'docs/papers/paper_2.pdf'}\n",
      "{'page': 7, 'source': 'docs/papers/paper_2.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The paper the chunk is from, should be one of `docs/papers/paper_1.pdf`, `docs/papers/paper_2.pdf`, or `docs/papers/paper_3.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the paper\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"paper\"\n",
    "llm = OpenAI(temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about yolox in the third paper?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap our vectorstore\n",
    "llm = OpenAI(temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alanm\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alanm\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alanm\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alanm\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "YOLOX [7] detector from GDRNPP has the top performance of 77.3 AP C. Mask R-CNN [11] from CosyPose only achieves 60.5 AP C(-16.8 AP C). YOLOX is relatively insensitive to the image domain, improving only +3.5 APC(#1−#2 in Tab. 4) when trained also on real images.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "\"1 GDRNPPDet YOLOX 2022 RGB PBR+real 77.3 .081\", \"2 GDRNPPDet YOLOX 2022 RGB PBR 73.8 .081\"\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about yolox?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alanm\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alanm\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alanm\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alanm\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "YOLOX [7] detector from GDRNPP has the top performance of 77.3 AP C. Mask R-CNN [11] from CosyPose only achieves 60.5 AP C(-16.8 AP C). YOLOX is relatively insensitive to the image domain, improving only +3.5 APC(#1−#2 in Tab. 4) when trained also on real images. Mask R-CNN yields +4.8 AP C(#6−#7) and FCOS [46] yields +5.4 AP C(#3−#4) in such a comparison.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "LM [13], LM-O [3], YCB-V [60]\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about yolox?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF\n",
    "loader = PyPDFLoader(\"docs/papers/paper_1.pdf\")\n",
    "pages = loader.load()\n",
    "all_page_text=[p.page_content for p in pages]\n",
    "joined_page_text=\" \".join(all_page_text)\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
    "splits = text_splitter.split_text(joined_page_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "svm_retriever = SVMRetriever.from_texts(splits,embedding)\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='ADD-SAUC of\\nADD(-S)AUC of\\nADD-SAUC of\\nADD(-S)AUC of\\nADD-SAUC of\\nADD(-S)\\n002master chef can 84.0 50.9 81.6 96.6 71.1 96.3 65.2 93.1 71.2 - -\\n003cracker box 76.9 51.7 80.5 84.9 63.5 97.0 88.8 91.0 83.6 - -\\n004sugar box 84.3 68.6 84.9 98.3 93.2 98.9 95.0 96.2 94.1 - -\\n005tomato soup can 80.9 66.0 78.2 96.1 88.9 96.5 91.9 92.4 86.1 - -\\n006mustard bottle 90.2 79.9 88.3 99.5 93.8 100.0 92.8 95.1 91.5 - -\\n007tuna ﬁshcan 87.9 70.4 62.2 95.1 85.1 99.4 94.2 96.1 87.7 - -\\n008pudding box 79.0 62.9 85.2 94.8 86.5 64.6 44.7 90.7 82.7 - -\\n009gelatin box 87.1 75.2 88.7 95.3 88.5 97.1 92.5 94.3 91.9 - -\\n010potted meat can 78.5 59.6 65.1 82.9 72.9 86.0 80.2 86.4 76.2 - -\\n011banana 85.9 72.3 51.8 96.0 85.2 96.3 85.8 91.3 81.2 - -\\n019pitcher base 76.8 52.5 91.2 98.8 94.3 99.9 98.5 94.6 90.1 - -\\n021bleach cleanser 71.9 50.5 74.8 94.4 80.5 94.2 84.3 90.3 81.2 - -\\n024bowl∗69.7 69.7 89.0 84.0 84.0 85.7 85.7 81.4 81.4 - -\\n025mug 78.0 57.7 81.5 96.9 87.6 99.6 94.0 91.3 81.4 - -\\n035power drill 72.8 55.1 83.4 91.9 78.7 97.5 90.1 92.3 85.5 - -\\n036wood block∗65.8 65.8 71.5 77.3 77.3 82.5 82.5 81.9 81.9 - -\\n037scissors 56.2 35.8 54.8 68.4 43.7 63.8 49.5 75.4 60.9 - -\\n040large marker 71.4 58.0 35.8 87.4 76.2 88.0 76.1 86.2 75.6 - -\\n051large clamp∗49.9 49.9 66.3 69.3 69.3 89.3 89.3 74.3 74.3 - -\\n052extra large clamp∗47.0 47.0 53.9 73.6 73.6 93.5 93.5 73.3 73.3 - -\\n061foam brick∗87.8 87.8 80.6 90.4 90.4 96.9 96.9 81.9 81.9 - -\\nMEAN 75.9 61.3 73.4 89.1 80.2 91.6 84.3 88.1 81.9 89.8 84.5')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major discussion in this paper?\"\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "docs_svm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='ods generally perform well, they usually lack in accuracy\\nwhen compared with approaches that instead rely on estab-\\nlishing 2D-3D correspondences prior to estimating the 6D\\npose [28, 15].\\nDifferently, this latter class of methods usually involves\\nsolving the 6D pose through a variant of the P nP/RANSAC\\nalgorithm. While such a paradigm provides good estimates,\\nit also suffers from several drawbacks. First, these methods\\nare usually trained with a surrogate objective for correspon-\\ndence regression, which does not necessarily reﬂect the ac-\\ntual 6D pose error after optimization. In practice, two sets\\nof correspondences can have the same average error while\\ndescribing completely different poses. Second, these ap-\\nproaches are not differentiable with respect to the estimated\\n6D pose, which limits learning. For instance, these meth-\\n1arXiv:2102.12145v3  [cs.CV]  9 Mar 2021 ods cannot be coupled with self-supervised learning from\\nunlabeled real data [55, 34, 1], as they require the computa-\\ntion of the pose to be fully differentiable in order to obtain a\\nsignal between data and pose. Finally, the RANSAC itera-\\ntive process can be very time-consuming when dealing with\\ndense correspondences.\\nTo summarize, while methods grounded on 2D-3D cor-\\nrespondences are dominating the ﬁeld, they still exhibit\\ndownsides due to the decoupling of the problem into two\\nseparate steps one of which not differentiable. Conse-\\nquently, some efforts have been devoted to enabling back-')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what did they say about yolox?\"\n",
    "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
    "docs_tfidf[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
